{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPhsxG8yvV2VIQU0f+wepoz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"as3bNls2izpz"},"outputs":[],"source":["!apt-get update\n","!apt-get install poppler-utils\n","!pip install pytesseract\n","!apt-get install tesseract-ocr\n","!pip install pdf2image\n","\n","\n","from PIL import Image\n","import pdf2image\n","import io\n","import pandas as pd\n"]},{"cell_type":"code","source":["import re\n","#the scanned text can contain unexpected chars\n","def correct_course(text):\n","  chars_to_remove = \"-\\\\'|;[]=_â€˜\"\n","  new_text = text.translate(str.maketrans('', '', chars_to_remove))\n","  return new_text\n","\n","string = \"sdlf--\\\\|;dfd'df[\"\n","print(correct_course(string))"],"metadata":{"id":"yW8m02WTlNez"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","#sometimes credit can extracted incorrectly, such as 1.0 can be taken 10\n","def correct_credit(text):\n","  new_text = text\n","  if text.find('.') ==-1 and len(text) > 1:\n","    new_text = text[:-1] + '.' + text[-1]\n","  return new_text\n","\n","print(correct_credit(\"20\"))"],"metadata":{"id":"Aa-SKTWBlcAf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","#check whether the grad is extracted correctly\n","def correct_grads(text):\n","  new_text = text\n","  validC = \"ABCFPN\"\n","  if not (validC.find(text) != -1 or (text.isdigit() and 0<= int(text) <=100)):\n","    return \"-1\"\n","  return text\n","\n","print(correct_grads(\"120\"))"],"metadata":{"id":"XqiRq11Xli-u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","def preprocess_page(text):\n","    # Remove newlines and extra whitespace\n","    # Split the string into lines, strip whitespace from each line, and filter out the empty lines\n","    non_empty_lines = [line.strip() for line in text.splitlines() if line.strip()]\n","\n","    # Join the non-empty lines back together\n","    text = \"\\n\".join(non_empty_lines)\n","    text = text.strip().replace(\"|\",'')\n","    #define the pattern that finds a row in the transcript table\n","    #corresponding to: the_name_of_the_course hours credit grade semester\n","    #during to the extraction accuracy, can have unexpected chars such as | ] -\n","    #for example\n","    #Math 36 1.0 | 99 1/2\n","    pattern = r\"(\\D+)(\\d+)\\D+(\\d+\\.\\d|\\d+)\\D+(\\d+|[A-Z])\\D+(\\d\\/\\d)\"\n","    lines = text.split(\"\\n\")\n","    left = []\n","    right = []\n","\n","    for line in lines:\n","      if line.find(\"/\") == -1:\n","        continue\n","\n","      matched = re.findall(pattern, line)\n","      #if matched, then it is a row of the table\n","      if matched != None and len(matched) > 0:\n","        print(matched)\n","        #corrected name of the course\n","        course = correct_course(matched[0][0])\n","\n","        #corrected credit of the course\n","        credit = correct_credit(matched[0][2])\n","\n","        #corrected grads of the course in 100 or ABCF or NP scale\n","        grads = correct_grads(matched[0][3])\n","\n","        #two tables in one page, scanned horizontal and need to process vertical\n","        #get the left table\n","        left.append([course, credit, grads])\n","        if(len(matched) == 2):\n","          #corrected name of the course\n","          course = correct_course(matched[1][0])\n","\n","          #corrected credit of the course\n","          credit = correct_credit(matched[1][2])\n","\n","          #corrected grads of the course in 100 or ABCF or NP scale\n","          grads = correct_grads(matched[1][3])\n","\n","          #two tables in one page, get the right table\n","          right.append([course, credit, grads])\n","\n","    finalresult = left + right\n","\n","    return finalresult"],"metadata":{"id":"-lfUTd-qraTS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sqlalchemy.engine.result import Result\n","import pytesseract\n","import cv2\n","import numpy as np\n","import imutils\n","\n","def extracttxt_pdf(pdf_path):\n","  # Define the path to the txt file\n","  txt_file = pdf_path[0:pdf_path.index(\".\")] + \".txt\"\n","  # Use pdf2image to convert the PDF file to a list of PIL images\n","  pages = pdf2image.convert_from_path(pdf_path)\n","\n","  result = []\n","  #write the extracted text into a file\n","  with open(txt_file, 'w') as file:\n","    # Loop through each page of the PDF\n","    for page in pages:\n","        #do noise reduction before extraction to improve accuracy\n","        # convert the image to a NumPy array\n","        image = cv2.cvtColor(np.array(page), cv2.COLOR_RGB2BGR)\n","        \n","        # convert the image to grayscale\n","        gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","        # Binarization\n","        # thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n","\n","        # Denoising using median filtering\n","        # denoised = cv2.medianBlur(thresh, 3)\n","        # apply Gaussian filtering\n","        filtered_img = cv2.GaussianBlur(gray_img, (5, 5), 0)\n","\n","        # Deskew\n","        # osd = pytesseract.image_to_osd(denoised)\n","        # matched = re.search(r\"Rotate: (\\d+.?\\d*)\",osd)\n","        # if(matched != None):\n","        #   angle = matched.group(1) \n","        # rotated = imutils.rotate_bound(denoised, int(angle))\n","\n","        # Contrast enhancement\n","        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n","        enhanced_image = clahe.apply(gray_img)\n","\n","        # define the minimum and maximum pixel values\n","        # min_val, max_val, _, _ = cv2.minMaxLoc(enhanced_image)\n","\n","        # stretch the pixel values to the range of 0-255\n","        # stretched_img = np.uint8((enhanced_image - min_val) * (255 / (max_val - min_val)))\n","\n","\n","        # Use pytesseract to extract text from the page\n","        text = pytesseract.image_to_string(enhanced_image)\n","        res = preprocess_page(text)\n","\n","        result += res\n","        # write some text to the file\n","        file.write(text)\n","  return result\n","\n","res = extracttxt_pdf(\"Transcript.pdf\")\n"],"metadata":{"id":"fg-KgADRweDY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_excel(path, data):\n","  # Convert the data to a pandas DataFrame\n","  column_names = [\"Course\",\"Credit\",\"Grads\"]  \n","  df = pd.DataFrame(data, columns=column_names)\n","  df.head()\n","  # Save the DataFrame as an Excel file\n","  df.to_csv(path, index=False)"],"metadata":{"id":"jjyJ7wjavfWz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def to_nor(row):\n","  if row['Grads'] == 'P':\n","    return 'A'\n","  elif row['Grads'] == 'A' or row['Grads'] == 'B' or row['Grads'] == 'C':\n","    return row['Grads']\n","  elif row['Grads'] == 'N':\n","    return 'F'\n","  elif float(row['Grads']) >= 89.5:\n","    return 'A'\n","  elif float(row['Grads'])  >= 77.5:\n","    return 'B'\n","  elif float(row['Grads'])  >= 65.5:\n","    return 'C'\n","  elif float(row['Grads'])  >= 53.5:\n","    return 'D'\n","  elif float(row['Grads'])  >= 41.5:\n","    return 'E'\n","  else:\n","    return 'F' "],"metadata":{"id":"umSricpq6wHO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a function to right-align the text in a cell\n","def right_align(val):\n","    return str(val).rjust(10)\n","\n"],"metadata":{"id":"fL3G_WnSrL25"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compute_nor_grad(path):\n","  df = pd.read_csv(path)\n","  df['Nor_Grad'] = df.apply(to_nor, axis=1)\n","  # Define a dictionary to map Norwegian grades to numerical values\n","  norwegian_grades_map = {'A': 6, 'B': 5, 'C': 4, 'D': 3, 'E': 2, 'F': 1}\n","\n","  # Compute the numerical value of each Norwegian grade\n","  numerical_grades = [norwegian_grades_map[grade] for grade in df['Nor_Grad']]\n","  print(numerical_grades)\n","  df['Nor_Grad_Num'] = numerical_grades\n","  print(df.head())\n","  # Apply the right_align function to all cells in the dataframe\n","  df = df.applymap(right_align)   \n","  # Save the DataFrame as an Excel file\n","  df.to_csv(path, index=False)"],"metadata":{"id":"bwyEIluH4TPk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# generate a csv file from the scanned bachelor transcript and comput Norwegian grad\n","def processTranscript(filepath):\n","  res = extracttxt_pdf(filepath)\n","  generate_excel(filepath[0:filepath.index('.')] + \".csv\", res)\n","  compute_nor_grad(filepath[0:filepath.index('.')] + \".csv\")"],"metadata":{"id":"iC-7pCKs1nV4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#process bachelor transcript\n","processTranscript(\"Transcript.pdf\")"],"metadata":{"id":"TBicdrdBElW3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# New Section"],"metadata":{"id":"Zt9fRJDnjDra"}}]}