{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO9RJBrxnvOaoezznC9Qun3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rtfSJ39Szaay"},"outputs":[],"source":["!pip uninstall google-cloud-vision -y\n","\n","!pip install google-cloud-vision\n","!pip show google-cloud-vision"]},{"cell_type":"code","source":["import json\n","import re\n","import io\n","import os\n","from google.cloud import vision_v1\n","from google.cloud.vision_v1 import types\n","\n","#extract text using google cloud vision\n","def detect_text_ML(pdf_path, destination_path):\n","    \"\"\"OCR with PDF/TIFF as source files on local machine\"\"\"\n","    # Set the path to your Google Cloud service account key file\n","    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'optimal-via.json'\n","\n","    # Supported mime_types are: 'application/pdf' and 'image/tiff'\n","    mime_type = 'application/pdf'\n","\n","    client = vision_v1.ImageAnnotatorClient()\n","\n","    with io.open(pdf_path, 'rb') as pdf_file:\n","        content = pdf_file.read()\n","    #define the configuration of the input\n","    input_config = types.InputConfig(\n","        mime_type=mime_type, content=content)\n","    #define the service to be done\n","    feature = types.Feature(\n","        type=types.Feature.Type.DOCUMENT_TEXT_DETECTION)\n","\n","    #define the requests\n","    requests = types.AnnotateFileRequest(\n","        input_config=input_config, features=[feature])\n","    request = types.BatchAnnotateFilesRequest(requests=[requests])\n","    #batch_annotate_files takes BatchAnnotateFilesRequest as parameter\n","    response = client.batch_annotate_files(request)\n","\n","    #out put the text returned by response\n","    for response in response.responses:\n","        text = response.responses[0].full_text_annotation.text\n","        print(text)\n","detect_text_ML(\"Transcript.pdf\",\"Transcript.txt\")"],"metadata":{"id":"9r4YLjZVzjxg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip uninstall kraken\n","!pip install kraken\n"],"metadata":{"id":"CBlD6Xl_zmIr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import kraken\n","from kraken import binarization\n","from kraken.lib import models\n","from kraken import rpred\n","from kraken.pageseg import segment\n","from PIL import Image\n","import pdf2image\n","import io \n","\n","#extract text using kraken\n","def detecttxt_kraken(filepath):\n","  # Use pdf2image to convert the PDF file to a list of PIL images\n","  pages = pdf2image.convert_from_path(filepath)\n","  # Save images to disk\n","  for i, page in enumerate(pages):\n","      page.save(f\"transcript-{i}.png\", \"PNG\")\n","      # Open the image\n","      pdf_image = Image.open(f\"transcript-{i}.png\")\n","      # bw_im = binarization.nlbin(pdf_image)\n","\n","      # Segment the image into individual text lines using Kraken\n","      # Get the bounding box coordinates\n","      lines = segment(pdf_image.convert(\"1\"))\n","      text_direction = 'horizontal-lr'  # Example text direction\n","      bounds = {'boxes': lines['boxes'], 'text_direction': text_direction}\n","\n","      rec_model_path = 'en_best.mlmodel'\n","      model = models.load_any(rec_model_path)\n","\n","      # Use Kraken to recognize the text in the image\n","      # can only extract text in one line which are inside bounds\n","      pred_it = rpred.rpred(model, pdf_image, bounds,bidi_reordering=False)\n","\n","      print(lines['boxes'])\n","      # Print the recognized text\n","      for record in pred_it:\n","        print(record)\n","\n","detecttxt_kraken(\"Transcript.pdf\")"],"metadata":{"id":"pVBBYiB0zoSi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install easyocr\n","!pip install pdf2image\n","!sudo apt-get install poppler-utils"],"metadata":{"id":"pqrp-p7u0yFY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import easyocr\n","import pdf2image\n","from PIL import Image\n","import numpy as np\n","\n","#extract text using easyocr\n","def detecttxt_easyocr(filepath):\n","  # Open PDF file and get the number of pages\n","  pages = pdf2image.convert_from_path(filepath)\n","  # Save images to disk\n","  for i, page in enumerate(pages):\n","      page.save(f\"images-{i}.png\", \"PNG\")\n","\n","  # Initialize EasyOCR reader\n","  reader = easyocr.Reader(['en'])\n","\n","  # Loop over pages and extract text\n","  for i, page in enumerate(pages):\n","      result = reader.readtext(f\"images-{i}.png\")\n","      # Print the text\n","      for text in result:\n","        print(text[1])\n","\n","detecttxt_easyocr(\"Transcript.pdf\")"],"metadata":{"id":"9YEX-TTv0qTR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pytesseract\n","!apt-get install tesseract-ocr\n"],"metadata":{"id":"rw-_r6uJAY8Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pytesseract\n","import cv2\n","import numpy as np\n","import pdf2image\n","from PIL import Image\n","\n","def extracttxt_pytesseract(pdf_path):\n","  # Define the path to the txt file\n","  txt_file = pdf_path[0:pdf_path.index(\".\")] + \".txt\"\n","  # Use pdf2image to convert the PDF file to a list of PIL images\n","  pages = pdf2image.convert_from_path(pdf_path)\n","\n","  #write the extracted text into a file\n","  with open(txt_file, 'w') as file:\n","    # Loop through each page of the PDF\n","    for page in pages:\n","        #do noise reduction before extraction to improve accuracy\n","        # convert the image to a NumPy array\n","        image = cv2.cvtColor(np.array(page), cv2.COLOR_RGB2BGR)\n","        # apply Gaussian filtering\n","        # filtered_img = cv2.GaussianBlur(image, (5, 5), 0)\n","        # convert the image to grayscale\n","        gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","        # define the minimum and maximum pixel values\n","        min_val, max_val, _, _ = cv2.minMaxLoc(gray_img)\n","\n","        # stretch the pixel values to the range of 0-255\n","        stretched_img = np.uint8((gray_img - min_val) * (255 / (max_val - min_val)))\n","\n","\n","        # Use pytesseract to extract text from the page\n","        text = pytesseract.image_to_string(stretched_img)\n","\n","        # write some text to the file\n","        file.write(text)\n","  return txt_file\n","\n","extracttxt_pytesseract(\"Transcript.pdf\")"],"metadata":{"id":"wHnbfHCwAR-y"},"execution_count":null,"outputs":[]}]}